%Este trabalho está licenciado sob a Licença Creative Commons Atribuição-CompartilhaIgual 3.0 Não Adaptada. Para ver uma cópia desta licença, visite http://creativecommons.org/licenses/by-sa/3.0/ ou envie uma carta para Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

\documentclass[../livro.tex]{subfiles}  %%DM%%Escolher document class and options article, etc

%define o diretório principal
\providecommand{\dir}{..}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%INICIO DO DOCUMENTO%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\chapter{Semanas 6 e 7}



\section{Espaços vetoriais}

Nós vimos que um espaço vetorial (sobre o conjunto $\bR$ de escalares) é um conjunto $V$ equipado com as operações de soma de vetores e de multiplicação por escalar e que satisfazem as propriedades usuais dos espaços $\bR^n$.



\section{Bases de espaços vetoriais}


Uma \textbf{base} para um espaço vetorial $V$ é um conjunto $\cB$ que:
\begin{itemize}
	\item gera $V$ e;
	\item é linearmente independente.
\end{itemize}


\begin{example}
	$\bR^n$ é um espaço vetorial sobre $\bR$. Vimos anteriormente que os vetores
	\[
	\vec{e}_1 =
	\left[
	\begin{array}{c}
	1 \\
	0 \\
	\vdots \\
	0
	\end{array}
	\right], \vec{e}_2 =
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\vdots \\
	0
	\end{array}
	\right], \cdots, \vec{e}_n =
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots \\
	1
	\end{array}
	\right]
	\] formam um conjunto linearmente independentes. E também é verdade que eles geram $\bR^n$, pois qualquer vetor pode ser escrito como combinação linear deles:
	\[
	\vec{v} =
	\left[
	\begin{array}{c}
	x_1 \\
	x_2 \\
	\vdots \\
	x_n
	\end{array}
	\right] = x_1
	\left[
	\begin{array}{c}
	1 \\
	0 \\
	\vdots \\
	0
	\end{array}
	\right] + x_2
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\vdots \\
	0
	\end{array}
	\right] + \cdots + x_n
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots \\
	1
	\end{array}
	\right] = x_1 \vec{e}_1 + x_2 \vec{e}_2 + \cdots + x_n \vec{e}_n.
	\] Portanto, o conjunto de $n$ elementos $\{\vec{e}_1, \vec{e}_2, \dots, \vec{e}_n\}$ é uma base de $\bR^n$.
\end{example}



Várias propriedades interessantes aparecem naturalmente como consequência da definição de base. Suponhamos que um conjunto $\cB = \{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_d\} \subset V$ seja uma base de um espaço vetorial $V$. Já que $\Span \cB = V$, qualquer elemento de $V$ pode ser representado como
\[
\vec{v} = x_1 \vec{v}_1 + x_2 \vec{v}_2 + \cdots + x_d \vec{v}_d.
\] Além disso, o fato de ser $\cB$ um conjunto linearmente independente nos diz que esta forma de representar o vetor $\vec{v}$ é única! De fato, vamos verificar que qualquer outra representação é, na verdade, a mesa que tínhamos acima: se tivermos
\[
\vec{v} = k_1 \vec{v}_1 + k_2 \vec{v}_2 + \cdots + k_d \vec{v}_d,
\] deveremos também ter
\[
(x_1-k_1) \vec{v}_1 + (x_2-k_2) \vec{v}_2 + \cdots + (x_d-k_d) \vec{v}_d = \vec{v} - \vec{v} = \vec{0}.
\] Sendo a base $\cB$ formada por vetores LI, concluimos que os coeficientes devem ser nulos, isto é, $x_1=k_1, x_2=k_2,\dots,x_d=k_d$. Portanto,

\begin{center}
  ''todo vetor pode ser representado de maneira única como combinação linear dos elementos de uma base.''
\end{center}

Uma segunda propriedade que é fundamental é a seguinte:
\begin{center}
  ''toda base de um espaço vetorial fixado possui o mesmo número de elementos.''
\end{center}

\begin{proof}[Justificativa] Se tivéssemos duas bases $\cB_1 = \{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_d\} \subset V$ e $\cB_2 = \{\vec{w}_1, \vec{w}_2, \dots, \vec{w}_k\} \subset V$ de um espaço vetorial $V$ com $k<d$, nós poderíamos escrever os elementos da base $\cB_1$ como combinações lineares dos elementos da base $\cB_2$:
	\[
	\left\{
	\begin{array}{rcl}
	\vec{v}_1 &=& a_{11} \vec{w}_1 + a_{21} \vec{w}_2 + \cdots + a_{k1} \vec{w}_k \\
	\vec{v}_2 &=& a_{12} \vec{w}_1 + a_{22} \vec{w}_2 + \cdots + a_{k2} \vec{w}_k \\ 
	&     \vdots& \\
	\vec{v}_d &=& a_{1d} \vec{w}_1 + a_{2d} \vec{w}_2 + \cdots + a_{kd} \vec{w}_k \\
	\end{array}
	\right.
	\] O problema é que, se tivéssemos $k<d$, então a equação 
	\begin{equation}\label{1111}
	b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_d \vec{v}_d = \vec{0}
	\end{equation} possuiria soluções não triviais, contradizendo o fato de ser $\cB_1$ um conjunto linearmente independente. De fato, utilizando que $\cB_1$ é linearmente independente, encontrar $b_1, b_2, \dots, b_k$ na equação \eqref{1111} fica equivalente a resolver
	\[
	\left[
	\begin{array}{cccc}
	a_{11} & a_{12} & \cdots & a_{1d} \\
	a_{21} & a_{22} & \cdots & a_{2d} \\
	\vdots & \vdots &        & \vdots \\
	a_{k1} & a_{k2} & \cdots & a_{kd} \\
	\end{array}
	\right] 
	\left[
	\begin{array}{c}
	b_1 \\
	b_2 \\
	\vdots  \\
	b_d \\
	\end{array}
	\right] = 
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots  \\
	0 \\
	\end{array}
	\right],
	\] que possui soluções não triviais quando $k<d$.
	
	Argumentando de forma parecida, concluimos também que não podemos ter $d<k$. Portanto, $d=k$.
\end{proof}


O número de elementos de uma base de $V$ é chamado de \textbf{dimensão} do espaço vetorial $V$. A dimensão de $V$, pelo que vimos até agora, indica o número de parâmetros necessários para representar qualquer vetor de $V$.

Quando um vetor $\vec{v}$ é escrito em termos dos elementos de uma base, é comum utilizarmos a notação
\[
\vec{v} = x_1 \vec{v}_1 + x_2 \vec{v}_2 + \cdots  + x_d \vec{v}_d =
\left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_{d-1} \\
x_d \\
\end{array}
\right]_{\cB} \text{ ou ainda } \big[ \vec{v} \big]_{\cB} =
\left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_{d-1} \\
x_d \\
\end{array}
\right].
\]

\begin{example}
	O conjunto
	\[
	\cP_3 (\bR) = \big\{ p(x) = a_3 x^3 + a_2 x^2 + a_1 x + a_0 \text{ tais que } a_0, a_1, a_2, a_3 \in \bR \big\}
	\] de todos os polinômios de grau 3 é um espaço vetorial. Uma base para este espaço pode ser encontrada ``de olho'': é fácil ver que o conjunto de polinômios
	\[
	\big\{ x^3, x^2, x, 1 \big\}
	\] gera o espaço $\cP_3 (\bR)$. Para ver que são LI, precisamos verificar que se tivermos
	\[
	a_3 x^3 + a_2 x^2 + a_1 x + a_0 = 0, \quad \text{para todo } x \in \bR,
	\] então todos os coeficientes devem ser nulos. Isto segue do Teorema Fundamental da Álgebra\footnote{Mais geralmente, o Teorema Fundamental da Álgebra afirma que todo polinômio não nulo de grau $n$ possui exatamente $n$ raízes complexas; logo, no máximo $n$ raízes reais.}, que diz que todo polinômio não nulo de grau $3$ possui exatamente $3$ raízes complexas; logo, no máximo $3$ raízes reais. Portanto, já que no nosso caso, todos os valores de $x$ reais são raízes, nosso polinômio deve ser o constante igual a zero, de modo que todos os coeficientes são zero.
	
	Concluimos desta maneira que $\cB = \big\{ x^3, x^2, x, 1 \big\}$ é uma base de $\cP_3 (\bR)$, que consequentemente tem dimensão $4.$
	
	Desta maneira, qualquer elemento de $\cP_3 (\bR)$ pode ser representado por $4$ parâmetros. Por exemplo,
	\[
	p(x) = x^3 - 2 x^2 + 3 \ \rightsquigarrow \ [p(x)]_\cB = \left[
	\begin{array}{c}
	1 \\
	-2 \\
	0 \\
	3 \\
	\end{array}
	\right],
	\]
	\[
	q(x) = 2 x^3 + x^2 + x -1 \ \rightsquigarrow \ [q(x)]_\cB = \left[
	\begin{array}{c}
	2 \\
	1 \\
	1 \\
	-1 \\
	\end{array}
	\right].
	\] Nota que a ordem que escrevemos os elementos de uma base altera as representações $[p]_\cB$ e $[q]_\cB$.
\end{example}


\begin{example}
	Em um curso de equações diferenciais, se aprende que o conjunto de todas as soluções de uma equação linear de segunda ordem da forma
	\[
	y''(t) + f(x) y'(x) + g(x) y(x) = 0
	\] é uma espaço vetorial cuja dimensão é 2. Desta forma, sabendo que $y_1(x) = e^{2x}$ e $y_2 (x) = e^{-x}$ satisfazem a equação
	\begin{equation}\label{eqn:edo}
	y''(t) - y'(x) -2 y(x) = 0,
	\end{equation} podemos concluir que todas as soluções desta EDO podem ser escritas como combinação linear destas duas:
	\[
	y(x) \text{ é solução de \eqref{eqn:edo} } \iff y(x) = C_1 e^{2x} + C_2 e^{-x}, \ \text{ para algumas constantes } C_1, C_2 \in \bR.
	\]
\end{example}


\subsection{Espaço nulo}

Vimos que o espaço nulo (núcleo) de uma matriz $A$ de ordem $m \times n$ é o conjunto definido por
\[
\Nul A = \big\{ \vec{x} \in \bR^n \, | \, A\vec{x} = \vec{0}  \big\}.
\] Nas notas da semana passada, vimos também o seguinte exemplo:

\begin{example}
	Encontrar uma base para o espaço nulo da matriz
	\[
	A = \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2 \\
	-1 & 2  & -2  & 0 & 2 \\
	6  & -4 & 1   & 1 & -4 \\
	\end{array}
	\right].
	\]
	Por escalonamento:
	\[
	A \sim \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2  \\
	0  & 2  & 1   & 1 & 4  \\
	0  & 4  & 17  & 5 & 16 \\
	\end{array}
	\right] \sim \cdots \sim \left[
	\begin{array}{ccccc}
	1  & 0  & 0  & 2/5 & 2/5  \\
	0  & 1  & 0  & 2/5 & 26/15  \\
	0  & 0  & 1  & 1/5 & 8/15 \\
	\end{array}
	\right] \sim 
	\left\{
	\begin{array}{ll}
	x_1 = - \frac{2}{5} x_4 - \frac{2}{5} x_5  \\
	\\
	x_2 = - \frac{2}{5} x_4 - \frac{26}{15} x_5  \\
	\\
	x_3 = - \frac{1}{5} x_4 - \frac{8}{15} x_5  \\
	\end{array}
	\right.
	\] Logo,
	\[
	\left[
	\begin{array}{c}
	x_1 \\
	x_2 \\
	x_3 \\
	x_4 \\
	x_5 \\
	\end{array}
	\right] = 
	x_4 \left[
	\begin{array}{c}
	-2/5 \\
	-2/5 \\
	-1/5 \\
	1 \\
	0 \\
	\end{array}
	\right] + x_5 
	\left[
	\begin{array}{c}
	-2/5 \\
	-26/15 \\
	-8/15 \\
	0 \\
	1 \\
	\end{array}
	\right]
	\] de modo que $\operatorname{dim} \Nul A = 2$ e uma base é
	\[
	\left\{
	\left[
	\begin{array}{c}
	-2/5 \\
	-2/5 \\
	-1/5 \\
	1 \\
	0 \\
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	-2/5 \\
	-26/15 \\
	-8/15 \\
	0 \\
	1 \\
	\end{array}
	\right]
	\right\}.
	\] Já que estes vetores são LI, temos uma base para $\Nul A. \ \lhd$
\end{example}

É sempre possível obter uma base para $\Nul A$ desta forma. Enfatizamos esta propriedade abaixo:
\begin{center}
  ''uma base para $\Nul A$ pode ser encontrada por escalonamento ao resolver o sistema homogêneo associado à matriz $A$. Além disso, a dimensão do espaço nulo é igual ao número de variáveis livres do sistema.''
\end{center}

\subsection{Espaço coluna}

Vimos também o espaço coluna de uma matriz $A$ de ordem $m \times n$, que é o espaço gerado pelas colunas de $A$:
\[
A =
\left[
\begin{array}{cccc}
| & | &  & | \\
\vec{a}_1 & \vec{a}_2 & \cdots & \vec{a}_n \\
| & | &        & | \\
\end{array}
\right] \rightsquigarrow
\Col A = \Span \{ \vec{a}_1, \vec{a}_2, \dots, \vec{a}_n\}.
\] Desta forma, a definição de $\Col A$ já deixa claro um conjunto gerador: as colunas de $A$!. Para determinar uma base, nós devemos ``excluir'' as colunas que podem ser geradas pelas demais, de modo a obter um conjunto linearmente independente.

\begin{center}
  ''Uma base para $\Col A$ é formada pelas colunas pivô da matriz $A$. Para descobrir quais são as colunas pivô, procedemos por escalonamento. As \textit{colunas da matriz original} formam uma base de $\Col A$. A dimensão do espaço coluna é igual ao número de colunas pivô da matriz.''
\end{center}

\begin{example}
	Encontrar uma base para o espaço coluna da matriz
	\[
	A = \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2 \\
	-1 & 2  & -2  & 0 & 2 \\
	6  & -4 & 1   & 1 & -4 \\
	\end{array}
	\right].
	\] Vimos acima que a forma escalonada reduzida de $A$ é
	\[
	A \sim
	\left[
	\begin{array}{ccccc}
	1  & 0  & 0  & 2/5 & 2/5  \\
	0  & 1  & 0  & 2/5 & 26/15  \\
	0  & 0  & 1  & 1/5 & 8/15 \\
	\end{array}
	\right],
	\] de modo que todas as colunas pivô são as três primeiras. Porntanto, uma base de $\Col A$ é
	\[
	\left\{
	\left[
	\begin{array}{c}
	1    \\
	-1  \\
	6    \\
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	0   \\
	2   \\
	-4   \\
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	3  \\
	-2 \\
	1  \\
	\end{array}
	\right]
	\right\}.
	\]
\end{example}









\section{Teorema do núcleo e da imagem}


Nas seções anteriores, vimos que
\[
\operatorname{dim} \Col A  = \operatorname{dim} \text{ da imagem de } A  = \text{ número de colunas pivô e }
\]
\[
\operatorname{dim} \Nul A = \text{ número de variáveis livres do sistema homogêneo associado}.
\] Ora, mas ou uma coluna é pivô ou sua variável associada é livre, de modo que temos o

\begin{theorem}[Teorema do núcleo e da imagem]
	Para qualquer matriz $A$ de ordem $m\times n$, temos
	\[
	\boxed{\operatorname{dim} \Col A + \operatorname{dim} \Nul A = n = \text{ número de colunas de } A.}
	\]
\end{theorem}

\begin{remark}
	A dimensão do espaço coluna de $A$ ou, o que é a mesma coisa, dimensão da imagem da transformação linear $\vec{x} \mapsto A\vec{x}$, é também conhecida na literatura como o \textbf{posto de} $A$. Assim, o Teorema do núcleo e da imagem pode ser reenunciado como: Se $A$ é uma matriz $m\times n$, então
	\[
	\operatorname{posto} A + \operatorname{dim} \Nul A = n.
	\]
\end{remark}

\begin{remark}
	O teorema afirma que há uma relação entre as dimensões dos espaços coluna e nulo. No entanto, não esqueça que estes são subespaços de universos diferentes! Temos 
	\[
	\Nul A \subseteq \bR^n \text{ enquanto que } \Col A \subseteq \bR^m.
	\]
\end{remark}

Apesar da conclusão do teorema parecer simples, é muito útil na análise de sistemas lineares.

\begin{example}
	Todo sistema linear de ordem $5 \times 9$ deve possuir um espaço nulo de dimensão $4$ ou mais. De fato, como a matriz associada tem apenas cinco linhas, pode ter no máximo $5$ posições de pivô, de modo que
	\[
	\operatorname{dim} \Col A \le 5.
	\] Portanto
	\[
	\operatorname{dim} \Nul A = 9 - \operatorname{dim} \Col A \ge 9 - 5 = 4.
	\] Desta forma, se resolvermos um sistema homogêneo desta ordem e encontrarmos um conjunto solução de dimensão 3, certamente  há algum um erro nas contas!
\end{example}















\section{Matriz de mudança de coordenadas}

Se conhecemos as coordenadas do vetor $\vec{x}$ em uma base $\cB = \big\{ \vec{v}_1, \vec{v}_2, \dots, \vec{v}_n \big\}$:
\[
\big[ \vec{x} \big]_{\cB} =
\left[
\begin{array}{c}
b_1 \\
b_2 \\
\vdots \\
b_n \\
\end{array}
\right]_{\cB} = b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_n \vec{v}_n,
\] podemos obter as coordenadas usuais (na base canônica) de $\vec{x}$ de forma sistemática. Queremos descobrir $x_1, x_2, \dots, x_n$ tais que 
\[
\vec{x} = \left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_n \\
\end{array}
\right] = x_1 \vec{e}_1 + x_2 \vec{e}_2 + \cdots + x_n \vec{e}_n.
\] Uma maneira é considerar a matriz cujas colunas são os vetores $\vec{v}_i$:
\[
A =
\left[
\begin{array}{cccc}
| & | &  & | \\
\vec{v}_{1} & \vec{v}_{2} & \cdots & \vec{v}_{n} \\
| & | &  & | \\
\end{array}
\right] = 
\left[
\begin{array}{cccc}
v_{11} & v_{12} & \cdots & v_{1n} \\
v_{21} & v_{22} & \cdots & v_{2n} \\
\vdots & \vdots &        & \vdots \\
v_{m1} & v_{m2} & \cdots & v_{mn} \\
\end{array}
\right].
\] Funciona porque 
\begin{align*}
b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_n \vec{v}_n & = \sum_{j=1}^{n} b_j \vec{v}_j = \sum_{j=1}^{n} b_j \sum_{i=1}^{n} v_{ij} \vec{e}_i  = \sum_{i=1}^{n} \bigg(\sum_{j=1}^{n} b_j v_{ij}\bigg) \vec{e}_i \\
& = \bigg(\sum_{j=1}^{n} b_j v_{1j}\bigg) \vec{e}_1 + \bigg(\sum_{j=1}^{n} b_j v_{2j}\bigg) \vec{e}_2 + \cdots + \bigg(\sum_{j=1}^{n} b_j v_{nj}\bigg) \vec{e}_n.
\end{align*}
Assim, devemos ter
\[
\left\{
\begin{array}{lcl}
x_1 &=& v_{11} b_{1} + v_{12} b_{2} + \cdots + v_{1n} b_{n} \\
x_2 &=& v_{21} b_{1} + v_{22} b_{2} + \cdots + v_{2n} b_{n} \\
&\vdots& \\
x_n &=& v_{n1} b_{1} + v_{n2} b_{2} + \cdots + v_{nn} b_{n} \\
\end{array}
\right. \quad \text{i.e} \quad \vec{x} = A [\vec{x}]_{\cB}.
\]

A matriz $A$ construida como acima é chamada de \textbf{matriz de mudança de coordenadas} da base $\cB$ para a base usual (canônica) $\{ \vec{e}_1, \vec{e}_2, \dots, \vec{e}_n\}$.

A matriz de mudança de coordenadas da base canônica para a base $\cB$ pode ser obtida a partir da inversa de $A$:
\[
[\vec{x}]_{\cB} = A^{-1} \cdot \vec{x}.
\]

\begin{example}
	Consideramos a seguinte base para $\bR^2$:
	\[
	\cB = \left\{ 
	\left[
	\begin{array}{c}
	1 \\
	1 \\
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	-1 \\
	1 \\
	\end{array}
	\right]
	\right\}.
	\] Este conjunto é de fato uma base, pois são linearmente independentes e são dois (que é a dimensão de $\bR^2$). Sabendo que as coordenadas de $\vec{u}$ e $\vec{v}$ nesta base $\cB$ são
	\[
	[u]_{\cB} = 
	\left[
	\begin{array}{c}
	1 \\
	1 \\
	\end{array}
	\right]_{\cB} \quad \text{e} \quad 
	[v]_{\cB} =
	\left[
	\begin{array}{c}
	3 \\
	-1 \\
	\end{array}
	\right]_{\cB},
	\] encontrar as componentes de $\vec{u}$ e $\vec{v}$ na base canônica $\{ \vec{e}_1, \vec{e}_2\}$ de $\bR^2$.
	
	Pelo que analisamos acima, a matriz de mudança de coordenadas que procuramos é a matriz
	\[
	A = 
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1 \\
	\end{array}
	\right]
	\] Logo,
	\[
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1 \\
	\end{array}
	\right] \left[
	\begin{array}{c}
	1 \\
	1 \\
	\end{array}
	\right]_{\cB} = 
	\left[
	\begin{array}{c}
	0 \\
	2 \\
	\end{array}
	\right] \text{ e } \vec{v} = 
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1 \\
	\end{array}
	\right] \left[
	\begin{array}{c}
	3 \\
	-1 \\
	\end{array}
	\right]_{\cB} =
	\left[
	\begin{array}{c}
	4 \\
	2 \\
	\end{array}
	\right].
	\]
\end{example}


\begin{remark}
	A matriz de mudança de coordenadas é uma forma de trocar de uma base para outra de forma sistemática. Com o intuito de tornar mais intuitiva a construção, vamos repetir a argumentação que fizemos no início desta seção para o caso $2\times 2$. Na base $\cB$ do exemplo anterior, a representação
	\[
	\left[
	\begin{array}{c}
	b_1 \\
	b_2 \\
	\end{array}
	\right]_{\cB} \text{ significa que } \vec{v} = b_1 \cdot \left[
	\begin{array}{c}
	1 \\
	1 \\
	\end{array}
	\right] + b_2 \cdot 
	\left[
	\begin{array}{c}
	-1 \\
	1 \\
	\end{array}
	\right].
	\] Os vetores da base $\cB$ são representados na base canônica por
	\[
	\left[
	\begin{array}{c}
	1 \\
	1 \\
	\end{array}
	\right] = 
	\left[
	\begin{array}{c}
	1 \\
	0 \\
	\end{array}
	\right] + 
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\end{array}
	\right] = \vec{e}_1 + \vec{e}_2 \quad \text{e} \quad 
	\left[
	\begin{array}{c}
	-1 \\
	1 \\
	\end{array}
	\right] =
	\left[
	\begin{array}{c}
	-1 \\
	0 \\
	\end{array}
	\right] +
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\end{array}
	\right] = - \vec{e}_1 + \vec{e}_2.
	\] Logo,
	\[
	\vec{v} = b_1 \left(  \vec{e}_1 + \vec{e}_2 \right) + b_2 \left(  - \vec{e}_1 + \vec{e}_2  \right) = (b_1 - b_2) \vec{e}_1 + (b_1 + b_2) \vec{e}_2,
	\] de modo que as componentes de $\vec{v}$ na base canônica são
	\[
	\left\{
	\begin{array}{ll}
	x_1 = b_1 - b_2 \\
	x_2 = b_1 + b_2
	\end{array}
	\right..
	\] Em notação matricial:
	\[
	\left[
	\begin{array}{c}
	x_1 \\
	x_2 \\
	\end{array}
	\right] = 
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1 \\
	\end{array}
	\right]
	\left[
	\begin{array}{c}
	b_1  \\
	b_2  \\
	\end{array}
	\right]
	\]
\end{remark}



\end{document} 